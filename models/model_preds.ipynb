{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"model_preds.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyNAtKKolXy+HH/DNww4mZ+b"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"FanptliVpd6G"},"source":["# Create Model & Load Saved Weights"]},{"cell_type":"code","metadata":{"id":"UsJKtPK2p5nI","executionInfo":{"status":"ok","timestamp":1615456182541,"user_tz":360,"elapsed":2219,"user":{"displayName":"Ngoc Phan","photoUrl":"","userId":"09481603094395391329"}}},"source":["\"\"\"\r\n","ResNet-18\r\n","Reference:\r\n","[1] K. He et al. Deep Residual Learning for Image Recognition. CVPR, 2016\r\n","[2] K. He, X. Zhang, S. Ren, and J. Sun. Delving deep into rectifiers:\r\n","Surpassing human-level performance on imagenet classification. In\r\n","ICCV, 2015.\r\n","\"\"\"\r\n","\r\n","from keras.callbacks import EarlyStopping\r\n","from keras.layers import Dense, Conv2D,  MaxPool2D, Flatten, GlobalAveragePooling2D,  BatchNormalization, Layer, Add\r\n","from keras.models import Sequential\r\n","from keras.models import Model\r\n","import tensorflow as tf\r\n","\r\n","class ResnetBlock(Model):\r\n","    \"\"\"\r\n","    A standard resnet block.\r\n","    \"\"\"\r\n","\r\n","    def __init__(self, channels: int, down_sample=False):\r\n","        \"\"\"\r\n","        channels: same as number of convolution kernels\r\n","        \"\"\"\r\n","        super().__init__()\r\n","\r\n","        self.__channels = channels\r\n","        self.__down_sample = down_sample\r\n","        self.__strides = [2, 1] if down_sample else [1, 1]\r\n","\r\n","        KERNEL_SIZE = (3, 3)\r\n","        # use He initialization, instead of Xavier (a.k.a 'glorot_uniform' in Keras), as suggested in [2]\r\n","        INIT_SCHEME = \"he_normal\"\r\n","\r\n","        self.conv_1 = Conv2D(self.__channels, strides=self.__strides[0],\r\n","                             kernel_size=KERNEL_SIZE, padding=\"same\", kernel_initializer=INIT_SCHEME)\r\n","        self.bn_1 = BatchNormalization()\r\n","        self.conv_2 = Conv2D(self.__channels, strides=self.__strides[1],\r\n","                             kernel_size=KERNEL_SIZE, padding=\"same\", kernel_initializer=INIT_SCHEME)\r\n","        self.bn_2 = BatchNormalization()\r\n","        self.merge = Add()\r\n","\r\n","        if self.__down_sample:\r\n","            # perform down sampling using stride of 2, according to [1].\r\n","            self.res_conv = Conv2D(\r\n","                self.__channels, strides=2, kernel_size=(1, 1), kernel_initializer=INIT_SCHEME, padding=\"same\")\r\n","            self.res_bn = BatchNormalization()\r\n","\r\n","    def call(self, inputs):\r\n","        res = inputs\r\n","\r\n","        x = self.conv_1(inputs)\r\n","        x = self.bn_1(x)\r\n","        x = tf.nn.relu(x)\r\n","        x = self.conv_2(x)\r\n","        x = self.bn_2(x)\r\n","\r\n","        if self.__down_sample:\r\n","            res = self.res_conv(res)\r\n","            res = self.res_bn(res)\r\n","\r\n","        # if not perform down sample, then add a shortcut directly\r\n","        x = self.merge([x, res])\r\n","        out = tf.nn.relu(x)\r\n","        return out\r\n","\r\n","class ResNet18(Model):\r\n","\r\n","    def __init__(self, num_classes, **kwargs):\r\n","        \"\"\"\r\n","            num_classes: number of classes in specific classification task.\r\n","        \"\"\"\r\n","        super().__init__(**kwargs)\r\n","        self.conv_1 = Conv2D(64, (7, 7), strides=2,\r\n","                             padding=\"same\", kernel_initializer=\"he_normal\")\r\n","        self.init_bn = BatchNormalization()\r\n","        self.pool_2 = MaxPool2D(pool_size=(2, 2), strides=2, padding=\"same\")\r\n","        self.res_1_1 = ResnetBlock(64)\r\n","        self.res_1_2 = ResnetBlock(64)\r\n","        self.res_2_1 = ResnetBlock(128, down_sample=True)\r\n","        self.res_2_2 = ResnetBlock(128)\r\n","        self.res_3_1 = ResnetBlock(256, down_sample=True)\r\n","        self.res_3_2 = ResnetBlock(256)\r\n","        self.res_4_1 = ResnetBlock(512, down_sample=True)\r\n","        self.res_4_2 = ResnetBlock(512)\r\n","        self.avg_pool = GlobalAveragePooling2D()\r\n","        self.flat = Flatten()\r\n","        self.fc = Dense(num_classes, activation=\"softmax\")\r\n","\r\n","    def call(self, inputs):\r\n","        out = self.conv_1(inputs)\r\n","        out = self.init_bn(out)\r\n","        out = tf.nn.relu(out)\r\n","        out = self.pool_2(out)\r\n","        for res_block in [self.res_1_1, self.res_1_2, self.res_2_1, self.res_2_2, self.res_3_1, self.res_3_2, self.res_4_1, self.res_4_2]:\r\n","            out = res_block(out)\r\n","        out = self.avg_pool(out)\r\n","        out = self.flat(out)\r\n","        out = self.fc(out)\r\n","        return out"],"execution_count":1,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UD5iKwoXpmDq","executionInfo":{"status":"ok","timestamp":1615456184118,"user_tz":360,"elapsed":3787,"user":{"displayName":"Ngoc Phan","photoUrl":"","userId":"09481603094395391329"}},"outputId":"3b583ae3-157b-46fc-98a7-b025c4ab63e1"},"source":["# create model and load weights\r\n","model = ResNet18(10)\r\n","model.build(input_shape = (None,32,32,3))\r\n","model.compile(optimizer = \"adam\", loss='categorical_crossentropy', metrics=[\"accuracy\"])\r\n","\r\n","# load weights\r\n","model.load_weights('drive/MyDrive/app/resnet_18.h5')"],"execution_count":2,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:AutoGraph could not transform <bound method ResnetBlock.call of <__main__.ResnetBlock object at 0x7fe7401b8490>> and will run it as-is.\n","Cause: mangled names are not yet supported\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n","WARNING: AutoGraph could not transform <bound method ResnetBlock.call of <__main__.ResnetBlock object at 0x7fe7401b8490>> and will run it as-is.\n","Cause: mangled names are not yet supported\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"wdY1IZfyq8dd"},"source":["# Prediction"]},{"cell_type":"code","metadata":{"id":"d_qSZVdUq-Zd","executionInfo":{"status":"ok","timestamp":1615456184120,"user_tz":360,"elapsed":3784,"user":{"displayName":"Ngoc Phan","photoUrl":"","userId":"09481603094395391329"}}},"source":["from PIL import Image\r\n","import numpy as np\r\n","\r\n","def predict(classifier, image_path):\r\n","  # class label\r\n","  labels = ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\r\n","\r\n","  image = Image.open(image_path)\r\n","  #plt.show(image)\r\n","\r\n","  # resize image\r\n","  im = image.resize((32,32))\r\n","  \r\n","  # normalize the data.\r\n","  im = np.array(im).astype('float32') / 255.0\r\n","  im = np.expand_dims(im, axis=0)\r\n","\r\n","  # close image\r\n","  image.close()\r\n","\r\n","  # classify image\r\n","  pred = classifier.predict(im)\r\n","  index = np.argmax(pred, axis=1)[0]\r\n","\r\n","  print(image_path.split('/')[-1], ':', labels[index], pred[0][index])"],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tYDT9IsErMvF","executionInfo":{"status":"ok","timestamp":1615456185821,"user_tz":360,"elapsed":5481,"user":{"displayName":"Ngoc Phan","photoUrl":"","userId":"09481603094395391329"}},"outputId":"666657ea-661d-4570-bcb8-11d21a9dd8ad"},"source":["import glob\r\n","\r\n","for img in glob.glob(\"drive/MyDrive/app/data/images/*.jpg\"):\r\n","    predict(model, img)"],"execution_count":4,"outputs":[{"output_type":"stream","text":["horse.jpg : truck 0.57945496\n","cat.jpg : dog 0.5289625\n","car.jpg : automobile 0.99995077\n"],"name":"stdout"}]}]}